"""
═══════════════════════════════════════════════════════════════════
  HYPERED BRAIN ENGINE v18.0 — Agentic AI Architecture
═══════════════════════════════════════════════════════════════════

Architecture — 6-Layer Autonomous Network Intelligence:

  ┌─────────────────────────────────────────────────────────────────────┐
  │                    USER QUERY / TRIGGER                             │
  └────────────────────────────┬────────────────────────────────────────┘
                               │
  ┌────────────────────────────▼────────────────────────────────────────┐
  │  LAYER 0: PERCEPTION — Intent Classification & Strategy Planning    │
  │  ● NLU intent extraction (domain, complexity, devices, protocols)   │
  │  ● Strategy selection (reactive/proactive/forensic/predictive)      │
  │  ● Execution plan generation (ordered task graph with priorities)   │
  └────────────────────────────┬────────────────────────────────────────┘
                               │
  ┌────────────────────────────▼───────────────────────────────────────┐
  │  LAYER 1: EXECUTION — Adaptive Parallel Pipeline                   │
  │                                                                    │
  │  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌──────────────────────┐   │
  │  │ Script 1│  │ Script 2│  │ Script N│  │ AI-Directed Probes   │   │
  │  │ (batch) │  │ (batch) │  │ (batch) │  │ (dynamic commands    │   │
  │  │         │  │         │  │         │  │  generated by AI)    │   │
  │  └────┬────┘  └────┬────┘  └────┬────┘  └──────────┬───────────┘   │
  │       │            │            │                  │               │
  │  ┌────▼────────────▼────────────▼──────────────────▼──────────┐    │
  │  │            STREAMING FACT ACCUMULATOR                      │    │
  │  │  ● Facts deduplicated by (device, key, value) fingerprint  │    │
  │  │  ● Anomaly scoring: threshold + cross-device deviation     │    │
  │  │  ● Working memory: persists across passes + sessions       │    │
  │  └─────────────────────────────┬──────────────────────────────┘    │
  └────────────────────────────────┬───────────────────────────────────┘
                                   │
  ┌────────────────────────────────▼────────────────────────────────────┐
  │  LAYER 2: ANALYSIS — Progressive AI Reasoning                       │
  │  ● Analyze as results stream in (don't wait for all scripts)        │
  │  ● Cross-device correlation matrix (N×N anomaly adjacency)          │
  │  ● OSI-layer cascade detection (L1→L2→L3→L4→Service)                │
  │  ● Temporal correlation (commit time ↔ symptom onset)               │
  └────────────────────────────────┬────────────────────────────────────┘
                                   │
  ┌────────────────────────────────▼────────────────────────────────────┐
  │  LAYER 3: VALIDATION — Self-Audit & Gap Filling                     │
  │  ● Confidence scoring (evidence count × source diversity)           │
  │  ● Gap detector: AI requests specific show commands → auto-execute  │
  │  ● Contradiction detector: flag when facts from 2+ sources disagree │
  │  ● Loop gate: stop when confidence ≥ threshold OR max passes hit    │
  └────────────────────────────────┬────────────────────────────────────┘
                                   │
  ┌────────────────────────────────▼────────────────────────────────────┐
  │  LAYER 4: SYNTHESIS — Root Cause & Prescriptive Fix                 │
  │  ● Single root cause identification (lowest OSI layer)              │
  │  ● Cascading failure chain mapping                                  │
  │  ● Evidence-cited diagnosis (every claim → raw data reference)      │
  │  ● Remediation: exact Junos set/delete commands                     │
  │  ● Verification plan: commands to confirm fix                       │
  └────────────────────────────────┬────────────────────────────────────┘
                                   │
  ┌────────────────────────────────▼────────────────────────────────────┐
  │  LAYER 5: MEMORY — Cross-Session Learning                           │
  │  ● Issue fingerprints stored for pattern recognition                │
  │  ● Device baselines cached for anomaly deviation                    │
  │  ● Resolution database: past fix → outcome mapping                  │
  └────────────────────────────────────────────────────────────────────-┘

v18.0 Innovations:
  1. AGENTIC AI — The AI can request arbitrary show commands, not just
     pre-defined scripts. It acts as an autonomous network engineer.
  2. STREAMING ANALYSIS — Results analyzed as they arrive, not after
     all scripts complete. First insights in seconds, not minutes.
  3. ADAPTIVE CONCURRENCY — Concurrency auto-adjusts based on response
     latency. Slow gateway → back off. Fast → ramp up.
  4. FACT DEDUPLICATION — Facts fingerprinted by (device, key, value).
     No duplicate analysis across passes.
  5. WORKING MEMORY — Cross-session fact persistence. The brain
     remembers what it learned about your network last time.
  6. REACTIVE SCRIPTING — Scripts can generate dynamic follow-up
     commands based on what they find (e.g., deep-dive specific intf).
  7. CONTRADICTION DETECTION — When two data sources disagree about
     the same fact, the brain flags it and collects a third source.
  8. PRIORITY QUEUE — Critical scripts (connectivity, protocol state)
     execute first. Deep dives only if anomalies found.

Author: v18.0 Agentic Brain Architecture
"""

from __future__ import annotations

import asyncio
import json
import logging
import os
import re
import time
from collections import defaultdict
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Callable, Optional

logger = logging.getLogger("junos-bridge.hypered-brain")


# ══════════════════════════════════════════════════════════════
#  DATA STRUCTURES
# ══════════════════════════════════════════════════════════════

class BrainLayer(Enum):
    """The 4 layers of the Hypered Brain."""
    PERCEPTION = "perception"
    ANALYSIS = "analysis"
    VALIDATION = "validation"
    SYNTHESIS = "synthesis"


class ScriptCategory(Enum):
    """Categories for smart fact-gathering scripts."""
    CONNECTIVITY = "connectivity"
    PROTOCOL_STATE = "protocol_state"
    PERFORMANCE = "performance"
    CONFIGURATION = "configuration"
    HEALTH = "health"
    SECURITY = "security"
    TOPOLOGY = "topology"
    SERVICE = "service"
    DEEP_DIVE = "deep_dive"


class DataConfidence(Enum):
    """Confidence level for gathered data."""
    HIGH = "high"          # Multiple sources confirm
    MEDIUM = "medium"      # Single source, clear data
    LOW = "low"            # Indirect inference
    INSUFFICIENT = "insufficient"  # Not enough data


@dataclass
class SmartScript:
    """A smart fact-gathering script that runs on routers."""
    id: str
    name: str
    category: ScriptCategory
    description: str
    commands: list[dict]          # [{"device": "*"|"PE*"|"router", "command": "show ..."}]
    parse_rules: list[dict]       # Rules to extract structured facts from output
    triggers: list[str]           # Keywords that trigger this script
    depends_on: list[str] = field(default_factory=list)  # Script IDs this depends on
    priority: int = 5             # 1=highest, 10=lowest
    timeout: float = 60.0         # Max execution time
    follow_up: list[str] = field(default_factory=list)  # Script IDs to run if issues found


@dataclass
class GatheredFact:
    """A single fact gathered from a script execution."""
    source_script: str            # Script ID that produced this fact
    device: str                   # Router name
    category: str                 # What kind of fact
    key: str                      # Fact identifier (e.g., "ospf_neighbor_count")
    value: Any                    # The actual value
    raw_evidence: str             # Raw command output snippet
    confidence: DataConfidence = DataConfidence.MEDIUM
    timestamp: float = 0.0
    anomaly: bool = False         # Is this abnormal?
    expected: Any = None          # What was expected (if anomaly)


@dataclass
class ScriptResult:
    """Result from executing a smart script."""
    script_id: str
    script_name: str
    status: str                   # "success" | "failed" | "timeout" | "partial"
    facts: list[GatheredFact] = field(default_factory=list)
    raw_output: str = ""
    duration: float = 0.0
    devices_checked: list[str] = field(default_factory=list)
    anomalies_found: int = 0
    error: str = ""


@dataclass
class ValidationGap:
    """A gap identified during the validation layer."""
    description: str              # What's missing
    required_scripts: list[str]   # Script IDs needed to fill the gap
    reason: str                   # Why this gap matters
    priority: int = 5             # 1=urgent, 10=low
    related_facts: list[str] = field(default_factory=list)  # Fact keys that triggered this


@dataclass
class BrainState:
    """Complete state of the Hypered Brain during processing."""
    query: str
    layer: BrainLayer = BrainLayer.PERCEPTION
    pass_number: int = 1
    max_passes: int = 3
    all_facts: list[GatheredFact] = field(default_factory=list)
    script_results: list[ScriptResult] = field(default_factory=list)
    validation_gaps: list[ValidationGap] = field(default_factory=list)
    analysis_notes: list[str] = field(default_factory=list)
    confidence_score: float = 0.0
    confidence_threshold: float = 70.0
    start_time: float = 0.0
    layer_timings: dict = field(default_factory=dict)
    final_response: str = ""
    contradictions: list[str] = field(default_factory=list)


# ══════════════════════════════════════════════════════════════
#  v18.0: FACT ACCUMULATOR — Deduplicated Evidence Store
# ══════════════════════════════════════════════════════════════

class FactAccumulator:
    """Streaming fact store with deduplication and cross-device correlation.

    Facts are fingerprinted by (device, key, value) so the same fact
    discovered in multiple passes is counted once with increased confidence,
    not duplicated.  The accumulator also detects contradictions — when two
    sources report different values for the same (device, key).
    """

    def __init__(self):
        self._facts: dict[str, GatheredFact] = {}   # fingerprint → fact
        self._by_device: dict[str, list[str]] = defaultdict(list)  # device → [fingerprint]
        self._by_key: dict[str, list[str]] = defaultdict(list)     # key → [fingerprint]
        self._contradictions: list[tuple[GatheredFact, GatheredFact]] = []

    @staticmethod
    def _fingerprint(fact: GatheredFact) -> str:
        val = str(fact.value)[:120]
        return f"{fact.device}:{fact.key}:{val}"

    def ingest(self, facts: list[GatheredFact]) -> tuple[int, int, int]:
        """Add facts, returning (new_count, duplicate_count, contradiction_count)."""
        new, dup, contra = 0, 0, 0
        for f in facts:
            fp = self._fingerprint(f)
            if fp in self._facts:
                # Duplicate — boost confidence
                existing = self._facts[fp]
                if existing.confidence == DataConfidence.MEDIUM:
                    existing.confidence = DataConfidence.HIGH
                dup += 1
            else:
                # Check for contradiction: same (device, key) but different value
                for existing_fp in self._by_device.get(f.device, []):
                    existing = self._facts.get(existing_fp)
                    if existing and existing.key == f.key and str(existing.value) != str(f.value):
                        self._contradictions.append((existing, f))
                        contra += 1
                        break
                self._facts[fp] = f
                self._by_device[f.device].append(fp)
                self._by_key[f.key].append(fp)
                new += 1
        return new, dup, contra

    @property
    def all_facts(self) -> list[GatheredFact]:
        return list(self._facts.values())

    @property
    def anomalies(self) -> list[GatheredFact]:
        return [f for f in self._facts.values() if f.anomaly]

    @property
    def contradictions(self) -> list[tuple[GatheredFact, GatheredFact]]:
        return list(self._contradictions)

    def facts_for_device(self, device: str) -> list[GatheredFact]:
        return [self._facts[fp] for fp in self._by_device.get(device, []) if fp in self._facts]

    def device_anomaly_matrix(self) -> dict[str, dict[str, int]]:
        """Build a device × category anomaly count matrix for cross-correlation."""
        matrix: dict[str, dict[str, int]] = {}
        for f in self._facts.values():
            if f.anomaly:
                matrix.setdefault(f.device, defaultdict(int))
                matrix[f.device][f.category] += 1
        return dict(matrix)

    def __len__(self):
        return len(self._facts)


# ══════════════════════════════════════════════════════════════
#  v18.0: ADAPTIVE CONCURRENCY CONTROLLER
# ══════════════════════════════════════════════════════════════

class AdaptiveConcurrency:
    """Auto-adjust concurrency based on response latency.

    When the SSH gateway is overloaded, responses slow down and timeouts
    increase.  This controller monitors per-request latency and adjusts
    the semaphore window accordingly.

    Strategy:
      - Start at `initial` concurrent requests
      - If median latency > `slow_threshold_s` → decrease by 1 (min 1)
      - If median latency < `fast_threshold_s` → increase by 1 (max `ceiling`)
      - Re-evaluate every `window_size` completed requests
    """

    def __init__(self, initial: int = 3, ceiling: int = 6,
                 slow_threshold_s: float = 30.0, fast_threshold_s: float = 10.0,
                 window_size: int = 4):
        self.current = initial
        self.ceiling = ceiling
        self.slow_threshold = slow_threshold_s
        self.fast_threshold = fast_threshold_s
        self.window_size = window_size
        self._latencies: list[float] = []
        self._semaphore = asyncio.Semaphore(initial)

    def record(self, latency: float):
        self._latencies.append(latency)
        if len(self._latencies) >= self.window_size:
            self._adapt()

    def _adapt(self):
        median = sorted(self._latencies)[len(self._latencies) // 2]
        old = self.current
        if median > self.slow_threshold and self.current > 1:
            self.current -= 1
        elif median < self.fast_threshold and self.current < self.ceiling:
            self.current += 1
        if old != self.current:
            self._semaphore = asyncio.Semaphore(self.current)
            logger.info(f"Adaptive concurrency: {old} -> {self.current} (median latency {median:.1f}s)")
        self._latencies.clear()

    @property
    def semaphore(self) -> asyncio.Semaphore:
        return self._semaphore


# ══════════════════════════════════════════════════════════════
#  v18.0: AI-DIRECTED PROBE — Agentic Command Execution
# ══════════════════════════════════════════════════════════════

@dataclass
class AIProbe:
    """A probe is a single show command the AI wants to run on a device.

    Unlike SmartScripts (pre-defined), probes are generated dynamically
    by the AI when it identifies specific data gaps.  This is the core
    of the agentic capability — the AI acts as an autonomous engineer.
    """
    device: str      # MCP router name
    command: str     # Junos show command
    reason: str      # Why the AI wants this data
    priority: int = 3  # 1=urgent, 5=nice-to-have


def extract_ai_probes(ai_analysis: str, device_map: dict,
                       executed_commands: set[str] | None = None) -> list[AIProbe]:
    """Parse AI analysis text to extract specific show commands it wants run.

    The AI is prompted to output lines like:
      PROBE: <device> | <show command> | <reason>

    This allows the AI to request arbitrary data beyond pre-defined scripts,
    making it truly agentic.
    """
    if executed_commands is None:
        executed_commands = set()

    probes = []
    # Match structured PROBE lines
    probe_matches = re.findall(
        r'PROBE:\s*(\S+)\s*\|\s*(show\s+[^|]+?)\s*\|\s*(.+)',
        ai_analysis, re.IGNORECASE
    )
    for device_hint, command, reason in probe_matches:
        # Resolve device name
        device_hint = device_hint.strip()
        cmd = command.strip().rstrip('.')
        reason = reason.strip()

        # Skip already-executed commands
        cmd_key = f"{device_hint}:{cmd}"
        if cmd_key in executed_commands:
            continue

        # Find the MCP device name
        mcp_name = None
        for mcp, hostname in device_map.items():
            if mcp.lower() == device_hint.lower() or hostname.lower() == device_hint.lower():
                mcp_name = mcp
                break

        if mcp_name:
            probes.append(AIProbe(device=mcp_name, command=cmd, reason=reason))
            executed_commands.add(cmd_key)

    # Also look for inline "show ..." commands directed at specific devices
    # Pattern: "run `show ospf neighbor` on PE1" or "PE1: show ospf neighbor"
    inline_patterns = [
        r'(?:run|execute|check)\s+`?(show\s+[^`]+?)`?\s+on\s+(\S+)',
        r'(\S+):\s*`?(show\s+[^`\n]+)`?',
    ]
    for pat in inline_patterns:
        for match in re.findall(pat, ai_analysis, re.IGNORECASE):
            if len(match) == 2:
                cmd, dev = (match[0].strip(), match[1].strip()) if 'show' in match[0].lower() else (match[1].strip(), match[0].strip())
                if not cmd.lower().startswith('show'):
                    continue
                cmd_key = f"{dev}:{cmd}"
                if cmd_key in executed_commands:
                    continue
                for mcp, hostname in device_map.items():
                    if mcp.lower() == dev.lower() or hostname.lower() == dev.lower():
                        probes.append(AIProbe(device=mcp, command=cmd, reason="AI-directed inline probe"))
                        executed_commands.add(cmd_key)
                        break

    return probes[:6]  # Cap at 6 probes per pass to avoid overload


async def execute_ai_probes(probes: list[AIProbe],
                             run_single_fn: Callable,
                             mcp_client, session_id: str,
                             concurrency: AdaptiveConcurrency,
                             timeout: float = 45.0) -> list[ScriptResult]:
    """Execute AI-directed probes and return them as ScriptResults.

    Each probe becomes a lightweight ScriptResult so it integrates
    seamlessly with the existing fact accumulator and analysis pipeline.
    """
    results = []

    async def _run_probe(probe: AIProbe) -> ScriptResult:
        t0 = time.time()
        try:
            async with concurrency.semaphore:
                output = await asyncio.wait_for(
                    run_single_fn(mcp_client, session_id, probe.command,
                                  probe.device, f"[probe] {probe.reason[:40]}"),
                    timeout=timeout,
                )
            elapsed = time.time() - t0
            concurrency.record(elapsed)
            return ScriptResult(
                script_id=f"probe_{probe.device}_{hash(probe.command) % 10000:04d}",
                script_name=f"AI Probe: {probe.command[:50]}",
                status="success",
                raw_output=f"=== {probe.device}: {probe.command} ===\n{output}",
                duration=round(elapsed, 2),
                devices_checked=[probe.device],
            )
        except asyncio.TimeoutError:
            concurrency.record(timeout)
            return ScriptResult(
                script_id=f"probe_{probe.device}_{hash(probe.command) % 10000:04d}",
                script_name=f"AI Probe: {probe.command[:50]}",
                status="timeout",
                raw_output=f"=== {probe.device}: {probe.command} === TIMEOUT ({timeout}s)",
                duration=timeout,
                devices_checked=[probe.device],
            )
        except Exception as e:
            return ScriptResult(
                script_id=f"probe_{probe.device}_{hash(probe.command) % 10000:04d}",
                script_name=f"AI Probe: {probe.command[:50]}",
                status="failed",
                error=str(e),
                devices_checked=[probe.device],
            )

    tasks = [_run_probe(p) for p in probes]
    raw_results = await asyncio.gather(*tasks, return_exceptions=True)
    for i, r in enumerate(raw_results):
        if isinstance(r, Exception):
            results.append(ScriptResult(
                script_id=f"probe_err_{i}",
                script_name=f"AI Probe (error)",
                status="failed",
                error=str(r),
            ))
        else:
            results.append(r)
    return results


# ══════════════════════════════════════════════════════════════
#  SMART FACT-GATHERING SCRIPTS LIBRARY
# ══════════════════════════════════════════════════════════════

SMART_SCRIPTS: dict[str, SmartScript] = {}


def _register_scripts():
    """Register all smart fact-gathering scripts."""
    global SMART_SCRIPTS

    # ── CONNECTIVITY SCRIPTS ─────────────────────────────────

    SMART_SCRIPTS["intf_health"] = SmartScript(
        id="intf_health",
        name="Interface Health Scanner",
        category=ScriptCategory.CONNECTIVITY,
        description="Scans all interfaces for link state, errors, CRC, drops, and flaps",
        commands=[
            {"device": "*", "command": "show interfaces terse"},
            {"device": "*", "command": "show interfaces extensive | match \"Physical|CRC|Errors|Flap|Input rate|Output rate\""},
        ],
        parse_rules=[
            {"pattern": r"(\S+)\s+up\s+down", "fact": "link_down", "anomaly": True},
            {"pattern": r"CRC Errors\s+(\d+)", "fact": "crc_errors", "threshold": 10, "anomaly_if_above": True},
            {"pattern": r"Input errors:\s+(\d+)", "fact": "input_errors", "threshold": 100, "anomaly_if_above": True},
            {"pattern": r"Carrier transitions:\s+(\d+)", "fact": "carrier_transitions", "threshold": 5, "anomaly_if_above": True},
        ],
        triggers=["interface", "link", "physical", "down", "flap", "error", "crc", "connectivity"],
        priority=1,
        follow_up=["intf_deep_dive"],
    )

    SMART_SCRIPTS["intf_deep_dive"] = SmartScript(
        id="intf_deep_dive",
        name="Interface Deep Dive",
        category=ScriptCategory.DEEP_DIVE,
        description="Deep analysis on specific interfaces flagged as problematic",
        commands=[
            {"device": "{flagged_device}", "command": "show interfaces {flagged_intf} extensive"},
            {"device": "{flagged_device}", "command": "show interfaces diagnostics optics {flagged_intf}"},
        ],
        parse_rules=[
            {"pattern": r"Laser output power\s+:\s+([\d.]+)\s+mW", "fact": "tx_power_mw"},
            {"pattern": r"Receiver signal.*power\s+:\s+([\d.]+)\s+mW", "fact": "rx_power_mw"},
            {"pattern": r"Last flapped\s+:\s+(.+?)(?:\s+\(|$)", "fact": "last_flap_time"},
        ],
        triggers=["optics", "light", "power", "sfp", "transceiver"],
        depends_on=["intf_health"],
        priority=8,
    )

    # ── PROTOCOL STATE SCRIPTS ───────────────────────────────

    SMART_SCRIPTS["ospf_state"] = SmartScript(
        id="ospf_state",
        name="OSPF State Analyzer",
        category=ScriptCategory.PROTOCOL_STATE,
        description="Comprehensive OSPF adjacency, interface type, and area analysis",
        commands=[
            {"device": "*", "command": "show ospf neighbor"},
            {"device": "*", "command": "show ospf interface brief"},
            {"device": "*", "command": "show ospf database summary | match \"Type|count\""},
        ],
        parse_rules=[
            {"pattern": r"(\d+\.\d+\.\d+\.\d+)\s+(\S+)\s+(Full|Init|ExStart|2Way|Down)", "fact": "ospf_neighbor"},
            {"pattern": r"(\S+)\s+PtToPt", "fact": "ospf_p2p_intf"},
            {"pattern": r"(\S+)\s+(?:DR|BDR|DROther)", "fact": "ospf_broadcast_intf"},
            {"pattern": r"Nbrs\s+0", "fact": "ospf_no_neighbors", "anomaly": True},
        ],
        triggers=["ospf", "adjacency", "neighbor", "area", "igp", "routing"],
        priority=2,
        follow_up=["ospf_deep"],
    )

    SMART_SCRIPTS["ospf_deep"] = SmartScript(
        id="ospf_deep",
        name="OSPF Deep Inspection",
        category=ScriptCategory.DEEP_DIVE,
        description="Deep OSPF analysis: timer mismatches, MTU, authentication, LSDB",
        commands=[
            {"device": "{flagged_device}", "command": "show ospf interface {flagged_intf} detail"},
            {"device": "{flagged_device}", "command": "show configuration protocols ospf"},
            {"device": "*", "command": "show ospf database router lsa-id {router_id} detail"},
        ],
        parse_rules=[
            {"pattern": r"Hello:\s+(\d+),\s+Dead:\s+(\d+)", "fact": "ospf_timers"},
            {"pattern": r"Type:\s+(\w+)", "fact": "ospf_intf_type"},
            {"pattern": r"Authentication type:\s+(\w+)", "fact": "ospf_auth"},
        ],
        triggers=["ospf timer", "ospf mtu", "ospf auth", "exstart", "init"],
        depends_on=["ospf_state"],
        priority=7,
    )

    SMART_SCRIPTS["isis_state"] = SmartScript(
        id="isis_state",
        name="IS-IS State Analyzer",
        category=ScriptCategory.PROTOCOL_STATE,
        description="IS-IS adjacency states, levels, metrics, and DIS election",
        commands=[
            {"device": "*", "command": "show isis adjacency"},
            {"device": "*", "command": "show isis interface"},
            {"device": "*", "command": "show isis database brief"},
        ],
        parse_rules=[
            {"pattern": r"(\S+)\s+(\S+)\s+(Up|Down|Init)", "fact": "isis_adjacency"},
            {"pattern": r"Down", "fact": "isis_adj_down", "anomaly": True},
        ],
        triggers=["isis", "is-is", "adjacency", "level", "dis", "net"],
        priority=2,
        follow_up=["isis_deep"],
    )

    SMART_SCRIPTS["isis_deep"] = SmartScript(
        id="isis_deep",
        name="IS-IS Deep Inspection",
        category=ScriptCategory.DEEP_DIVE,
        description="IS-IS configuration, authentication, metric analysis",
        commands=[
            {"device": "{flagged_device}", "command": "show configuration protocols isis"},
            {"device": "{flagged_device}", "command": "show isis database {system_id} extensive"},
        ],
        parse_rules=[
            {"pattern": r"wide-metrics-only", "fact": "isis_wide_metrics"},
            {"pattern": r"authentication-key", "fact": "isis_auth_configured"},
        ],
        triggers=["isis config", "isis metric", "isis auth"],
        depends_on=["isis_state"],
        priority=7,
    )

    SMART_SCRIPTS["bgp_state"] = SmartScript(
        id="bgp_state",
        name="BGP Session Analyzer",
        category=ScriptCategory.PROTOCOL_STATE,
        description="BGP session states, prefix counts, route reflector topology",
        commands=[
            {"device": "*", "command": "show bgp summary"},
            {"device": "*", "command": "show bgp neighbor | match \"Peer:|State:|Options:|Active prefixes\""},
        ],
        parse_rules=[
            {"pattern": r"(\d+\.\d+\.\d+\.\d+)\s+\d+\s+\d+\s+\d+\s+\d+\s+\S+\s+\S+\s+(\d+/\d+/\d+)\s+\d+:\d+:\d+\s+(Establ)", "fact": "bgp_established"},
            {"pattern": r"(\d+\.\d+\.\d+\.\d+)\s+\d+\s+\d+\s+\d+\s+\d+\s+\S+\s+\S+\s+\S+\s+\S+\s+(Active|Idle|Connect)", "fact": "bgp_not_established", "anomaly": True},
            {"pattern": r"Active prefixes:\s+(\d+)", "fact": "bgp_active_prefixes"},
            {"pattern": r"Received prefixes:\s+(\d+)", "fact": "bgp_received_prefixes"},
        ],
        triggers=["bgp", "peer", "session", "ibgp", "ebgp", "route reflector", "established", "active", "idle"],
        priority=2,
        follow_up=["bgp_deep"],
    )

    SMART_SCRIPTS["bgp_deep"] = SmartScript(
        id="bgp_deep",
        name="BGP Deep Inspection",
        category=ScriptCategory.DEEP_DIVE,
        description="BGP configuration, policies, prefix-limit, authentication analysis",
        commands=[
            {"device": "{flagged_device}", "command": "show configuration protocols bgp"},
            {"device": "{flagged_device}", "command": "show bgp neighbor {peer_ip}"},
            {"device": "{flagged_device}", "command": "show route advertising-protocol bgp {peer_ip} summary"},
        ],
        parse_rules=[
            {"pattern": r"import\s+(\S+)", "fact": "bgp_import_policy"},
            {"pattern": r"export\s+(\S+)", "fact": "bgp_export_policy"},
            {"pattern": r"prefix-limit.*maximum\s+(\d+)", "fact": "bgp_prefix_limit"},
            {"pattern": r"authentication-key", "fact": "bgp_auth_configured"},
        ],
        triggers=["bgp config", "bgp policy", "bgp prefix-limit", "bgp auth"],
        depends_on=["bgp_state"],
        priority=7,
    )

    SMART_SCRIPTS["ldp_mpls_state"] = SmartScript(
        id="ldp_mpls_state",
        name="LDP/MPLS State Analyzer",
        category=ScriptCategory.PROTOCOL_STATE,
        description="LDP session states, MPLS interface config, label bindings",
        commands=[
            {"device": "*", "command": "show ldp session"},
            {"device": "*", "command": "show ldp neighbor"},
            {"device": "*", "command": "show mpls interface"},
            {"device": "*", "command": "show route table inet.3 summary"},
        ],
        parse_rules=[
            {"pattern": r"(\d+\.\d+\.\d+\.\d+)\s+(Operational|Nonexistent|Closed)", "fact": "ldp_session"},
            {"pattern": r"Nonexistent", "fact": "ldp_nonexistent", "anomaly": True},
            {"pattern": r"inet\.3:\s+(\d+)\s+destinations", "fact": "inet3_routes"},
        ],
        triggers=["ldp", "mpls", "label", "lsp", "inet.3", "transport"],
        priority=2,
        follow_up=["ldp_deep"],
    )

    SMART_SCRIPTS["ldp_deep"] = SmartScript(
        id="ldp_deep",
        name="LDP/MPLS Deep Inspection",
        category=ScriptCategory.DEEP_DIVE,
        description="LDP configuration, MPLS label bindings, LSP paths",
        commands=[
            {"device": "{flagged_device}", "command": "show configuration protocols ldp"},
            {"device": "{flagged_device}", "command": "show configuration protocols mpls"},
            {"device": "{flagged_device}", "command": "show ldp database"},
            {"device": "{flagged_device}", "command": "show route table inet.3"},
        ],
        parse_rules=[
            {"pattern": r"interface\s+(\S+)", "fact": "mpls_interface"},
        ],
        triggers=["ldp config", "mpls config", "label database"],
        depends_on=["ldp_mpls_state"],
        priority=7,
    )

    # ── HEALTH SCRIPTS ───────────────────────────────────────

    SMART_SCRIPTS["system_health"] = SmartScript(
        id="system_health",
        name="System Health Scanner",
        category=ScriptCategory.HEALTH,
        description="CPU, memory, storage, alarms, core dumps, uptime",
        commands=[
            {"device": "*", "command": "show chassis alarms"},
            {"device": "*", "command": "show system core-dumps"},
            {"device": "*", "command": "show system uptime | match \"System booted|Current time|Time Source\""},
            {"device": "*", "command": "show system storage | match \"Filesystem|/dev/\""},
            {"device": "*", "command": "show chassis routing-engine | match \"CPU|Memory|Mastership|Model\""},
        ],
        parse_rules=[
            {"pattern": r"(\d+) alarms currently active", "fact": "active_alarms"},
            {"pattern": r"No alarms currently active", "fact": "no_alarms"},
            {"pattern": r"(\d+)\s+core dumps", "fact": "core_dump_count", "threshold": 0, "anomaly_if_above": True},
            {"pattern": r"(\d+)%\s+used", "fact": "storage_pct", "threshold": 85, "anomaly_if_above": True},
            {"pattern": r"CPU utilization\s+(\d+)\s+percent", "fact": "cpu_pct", "threshold": 80, "anomaly_if_above": True},
            {"pattern": r"Memory utilization\s+(\d+)\s+percent", "fact": "memory_pct", "threshold": 85, "anomaly_if_above": True},
        ],
        triggers=["health", "cpu", "memory", "storage", "alarm", "core dump", "uptime", "status"],
        priority=2,
    )

    SMART_SCRIPTS["commit_history"] = SmartScript(
        id="commit_history",
        name="Recent Commit History",
        category=ScriptCategory.CONFIGURATION,
        description="Recent configuration changes — correlate with issues",
        commands=[
            {"device": "*", "command": "show system commit"},
        ],
        parse_rules=[
            {"pattern": r"(\d+)\s+(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\s+\S+\s+by\s+(\S+)\s+via\s+(\S+)", "fact": "commit_entry"},
        ],
        triggers=["commit", "change", "config change", "who changed", "when"],
        priority=4,
    )

    # ── SERVICE SCRIPTS ──────────────────────────────────────

    SMART_SCRIPTS["vpn_state"] = SmartScript(
        id="vpn_state",
        name="VPN Service Analyzer",
        category=ScriptCategory.SERVICE,
        description="L3VPN/L2VPN instance states, route tables, PE-CE routing",
        commands=[
            {"device": "PE*", "command": "show route instance summary"},
            {"device": "PE*", "command": "show route table bgp.l3vpn.0 summary"},
            {"device": "PE*", "command": "show route table bgp.evpn.0 summary"},
        ],
        parse_rules=[
            {"pattern": r"(\S+)\s+vrf\s+(\d+)/(\d+)/(\d+)", "fact": "vrf_instance"},
            {"pattern": r"bgp\.l3vpn\.0:\s+(\d+)\s+destinations", "fact": "l3vpn_routes"},
            {"pattern": r"bgp\.evpn\.0:\s+(\d+)\s+destinations", "fact": "evpn_routes"},
        ],
        triggers=["vpn", "vrf", "l3vpn", "l2vpn", "evpn", "service", "customer"],
        depends_on=["bgp_state"],
        priority=4,
    )

    # ── SECURITY SCRIPTS ─────────────────────────────────────

    SMART_SCRIPTS["security_posture"] = SmartScript(
        id="security_posture",
        name="Security Posture Check",
        category=ScriptCategory.SECURITY,
        description="Firewall filters, RE protection, SSH config, NTP, SNMP",
        commands=[
            {"device": "*", "command": "show configuration system services | match \"ssh|telnet|ftp\""},
            {"device": "*", "command": "show configuration system ntp"},
            {"device": "*", "command": "show configuration firewall family inet filter PROTECT-RE | count"},
            {"device": "*", "command": "show configuration system login | match \"class|user\""},
        ],
        parse_rules=[
            {"pattern": r"telnet", "fact": "telnet_enabled", "anomaly": True},
            {"pattern": r"ssh\b", "fact": "ssh_enabled"},
            {"pattern": r"ntp server", "fact": "ntp_configured"},
            {"pattern": r"Count:\s+(\d+)\s+lines", "fact": "re_filter_lines"},
        ],
        triggers=["security", "firewall", "filter", "ssh", "ntp", "protect", "hardening"],
        priority=5,
    )

    # ── TOPOLOGY SCRIPTS ─────────────────────────────────────

    SMART_SCRIPTS["topology_scan"] = SmartScript(
        id="topology_scan",
        name="Live Topology Scanner",
        category=ScriptCategory.TOPOLOGY,
        description="LLDP, interface descriptions, loopbacks — build live topology",
        commands=[
            {"device": "*", "command": "show lldp neighbors"},
            {"device": "*", "command": "show interfaces descriptions"},
            {"device": "*", "command": "show interfaces lo0.0 | match \"Addresses\""},
        ],
        parse_rules=[
            {"pattern": r"(\S+)\s+(\S+)\s+(\S+)\s+(\S+)", "fact": "lldp_neighbor"},
            {"pattern": r"Local Address\s+:\s+(\d+\.\d+\.\d+\.\d+)", "fact": "loopback_ip"},
        ],
        triggers=["topology", "map", "diagram", "lldp", "neighbors", "network map"],
        priority=3,
    )

    # ── PERFORMANCE SCRIPTS ──────────────────────────────────

    SMART_SCRIPTS["perf_baseline"] = SmartScript(
        id="perf_baseline",
        name="Performance Baseline Check",
        category=ScriptCategory.PERFORMANCE,
        description="Interface utilization, queue stats, routing table sizes",
        commands=[
            {"device": "*", "command": "show interfaces queue | match \"Queue|Queued packets|Dropped\""},
            {"device": "*", "command": "show route summary | match \"inet.0|inet.3|Total\""},
            {"device": "*", "command": "show interfaces statistics | match \"Input rate|Output rate\""},
        ],
        parse_rules=[
            {"pattern": r"Dropped packets\s+:\s+(\d+)", "fact": "queue_drops", "threshold": 1000, "anomaly_if_above": True},
            {"pattern": r"inet\.0:\s+(\d+)\s+destinations", "fact": "inet0_routes"},
            {"pattern": r"Input\s+rate\s+:\s+(\d+)\s+bps", "fact": "input_rate_bps"},
            {"pattern": r"Output\s+rate\s+:\s+(\d+)\s+bps", "fact": "output_rate_bps"},
        ],
        triggers=["performance", "utilization", "bandwidth", "throughput", "queue", "drops", "capacity"],
        priority=4,
    )

    # ── REACHABILITY SCRIPTS ─────────────────────────────────

    SMART_SCRIPTS["reachability_matrix"] = SmartScript(
        id="reachability_matrix",
        name="Loopback Reachability Matrix",
        category=ScriptCategory.CONNECTIVITY,
        description="Ping all loopbacks from all routers to verify end-to-end reachability",
        commands=[
            {"device": "*", "command": "show route table inet.0 protocol direct | match lo0"},
        ],
        parse_rules=[
            {"pattern": r"(\d+\.\d+\.\d+\.\d+)/32", "fact": "loopback_address"},
        ],
        triggers=["reachability", "ping", "reach", "end-to-end", "connectivity matrix"],
        priority=3,
    )

    SMART_SCRIPTS["route_validation"] = SmartScript(
        id="route_validation",
        name="Route Table Validator",
        category=ScriptCategory.PROTOCOL_STATE,
        description="Validate route tables have expected entries, check next-hop resolution",
        commands=[
            {"device": "*", "command": "show route summary"},
            {"device": "*", "command": "show route table inet.3 summary"},
            {"device": "PE*", "command": "show route table bgp.l3vpn.0 summary"},
        ],
        parse_rules=[
            {"pattern": r"inet\.0:\s+(\d+)\s+destinations,\s+(\d+)\s+routes", "fact": "inet0_detail"},
            {"pattern": r"inet\.3:\s+(\d+)\s+destinations", "fact": "inet3_detail"},
        ],
        triggers=["route", "routing table", "inet.0", "inet.3", "next-hop"],
        priority=3,
    )


# Initialize the script library
_register_scripts()


# ══════════════════════════════════════════════════════════════
#  SMART SCRIPT SELECTOR — LAYER 0: PERCEPTION
# ══════════════════════════════════════════════════════════════

def select_scripts_for_query(query: str, available_scripts: Optional[dict[str, SmartScript]] = None,
                             previous_results: Optional[list[ScriptResult]] = None,
                             force_categories: Optional[list[ScriptCategory]] = None) -> list[SmartScript]:
    """Intelligently select which scripts to run based on the query.
    
    Uses keyword matching, dependency resolution, and previous result analysis
    to pick the optimal set of scripts.
    """
    if available_scripts is None:
        available_scripts = SMART_SCRIPTS

    query_lower = query.lower()
    selected = {}
    previous_ids = {r.script_id for r in (previous_results or [])}

    # ── Step 1: Match by trigger keywords ──
    for script_id, script in available_scripts.items():
        if script_id in previous_ids:
            continue  # Don't re-run already-executed scripts

        score = 0
        for trigger in script.triggers:
            if trigger in query_lower:
                score += len(trigger)  # Longer matches score higher

        if score > 0:
            selected[script_id] = (script, score)

    # ── Step 2: Force-include category scripts ──
    if force_categories:
        for script_id, script in available_scripts.items():
            if script.category in force_categories and script_id not in previous_ids:
                selected[script_id] = (script, 100)

    # ── Step 3: If query is broad (health/audit/check), include basics ──
    broad_keywords = ["health", "audit", "check", "status", "overview", "what's wrong",
                      "any issues", "is everything", "how is"]
    if any(kw in query_lower for kw in broad_keywords):
        basics = ["intf_health", "ospf_state", "bgp_state", "ldp_mpls_state",
                  "system_health", "isis_state"]
        for sid in basics:
            if sid in available_scripts and sid not in previous_ids:
                selected[sid] = (available_scripts[sid], 50)

    # ── Step 4: If nothing matched, run connectivity + protocol basics ──
    if not selected:
        basics = ["intf_health", "ospf_state", "bgp_state", "ldp_mpls_state", "system_health"]
        for sid in basics:
            if sid in available_scripts and sid not in previous_ids:
                selected[sid] = (available_scripts[sid], 10)

    # ── Step 5: Resolve dependencies ──
    final_scripts = {}
    for script_id, (script, score) in selected.items():
        # Add dependencies first
        for dep_id in script.depends_on:
            if dep_id in available_scripts and dep_id not in previous_ids and dep_id not in final_scripts:
                final_scripts[dep_id] = available_scripts[dep_id]
        final_scripts[script_id] = script

    # ── Step 6: Sort by priority (lower number = higher priority) ──
    sorted_scripts = sorted(final_scripts.values(), key=lambda s: s.priority)

    # ── Step 7: Limit to max 8 scripts per pass to avoid overload ──
    return sorted_scripts[:8]


def select_follow_up_scripts(results: list[ScriptResult],
                              available_scripts: Optional[dict[str, SmartScript]] = None) -> list[SmartScript]:
    """Based on anomalies found, select follow-up scripts for deeper investigation."""
    if available_scripts is None:
        available_scripts = SMART_SCRIPTS

    follow_ups = {}
    executed_ids = {r.script_id for r in results}

    for result in results:
        if result.anomalies_found > 0:
            script = available_scripts.get(result.script_id)
            if script:
                for fu_id in script.follow_up:
                    if fu_id in available_scripts and fu_id not in executed_ids:
                        follow_ups[fu_id] = available_scripts[fu_id]

    return sorted(follow_ups.values(), key=lambda s: s.priority)[:4]


# ══════════════════════════════════════════════════════════════
#  PARALLEL SCRIPT EXECUTOR
# ══════════════════════════════════════════════════════════════

async def execute_script(script: SmartScript,
                         device_map: dict,
                         run_batch_fn: Callable,
                         run_single_fn: Callable,
                         mcp_client, session_id,
                         context: Optional[dict] = None) -> ScriptResult:
    """Execute a single smart script and extract structured facts.
    
    Args:
        script: The SmartScript to execute
        device_map: {mcp_name: hostname}
        run_batch_fn: async function to run batch commands
        run_single_fn: async function to run single commands
        mcp_client: HTTP client for MCP
        session_id: MCP session ID
        context: Additional context from previous results (e.g., flagged devices)
    """
    t0 = time.time()
    result = ScriptResult(
        script_id=script.id,
        script_name=script.name,
        status="pending",
        devices_checked=[],
    )

    if context is None:
        context = {}

    all_outputs = []

    try:
        for cmd_spec in script.commands:
            device_pattern = cmd_spec["device"]
            command = cmd_spec["command"]

            # ── Resolve device pattern ──
            target_devices = []
            if device_pattern == "*":
                target_devices = list(device_map.keys())
            elif device_pattern.endswith("*"):
                prefix = device_pattern[:-1].lower()
                target_devices = [d for d in device_map.keys()
                                  if device_map[d].lower().startswith(prefix) or d.lower().startswith(prefix)]
            elif "{flagged_device}" in device_pattern:
                # Use flagged devices from context
                flagged = context.get("flagged_devices", [])
                target_devices = flagged[:3] if flagged else list(device_map.keys())[:2]
            else:
                # Specific device
                reverse_map = {v.lower(): k for k, v in device_map.items()}
                mcp = reverse_map.get(device_pattern.lower(), device_pattern)
                if mcp in device_map:
                    target_devices = [mcp]

            if not target_devices:
                target_devices = list(device_map.keys())[:3]

            # ── Resolve command placeholders ──
            resolved_command = command
            for placeholder, value in context.items():
                if isinstance(value, str):
                    resolved_command = resolved_command.replace(f"{{{placeholder}}}", value)

            # Remove unresolved placeholders — skip command if critical ones remain
            if re.search(r'\{[a-z_]+\}', resolved_command):
                continue

            # ── Execute ──
            try:
                if len(target_devices) > 1:
                    output = await asyncio.wait_for(
                        run_batch_fn(mcp_client, session_id, resolved_command,
                                     target_devices, f"[brain] {script.name}"),
                        timeout=script.timeout
                    )
                else:
                    output = await asyncio.wait_for(
                        run_single_fn(mcp_client, session_id, resolved_command,
                                      target_devices[0], f"[brain] {script.name}"),
                        timeout=script.timeout
                    )
                all_outputs.append(f"=== {resolved_command} ===\n{output}")
                result.devices_checked.extend(target_devices)
            except asyncio.TimeoutError:
                all_outputs.append(f"=== {resolved_command} === TIMEOUT")
            except Exception as e:
                all_outputs.append(f"=== {resolved_command} === ERROR: {e}")

        result.raw_output = "\n\n".join(all_outputs)
        result.devices_checked = list(set(result.devices_checked))

        # ── Extract facts using parse rules ──
        result.facts = _extract_facts(script, result.raw_output, device_map)
        result.anomalies_found = sum(1 for f in result.facts if f.anomaly)
        result.status = "success" if all_outputs else "failed"

    except Exception as e:
        result.status = "failed"
        result.error = str(e)
        logger.error(f"Script {script.id} failed: {e}")

    result.duration = round(time.time() - t0, 2)
    return result


def _extract_facts(script: SmartScript, raw_output: str,
                   device_map: dict) -> list[GatheredFact]:
    """Extract structured facts from raw command output using parse rules."""
    facts = []

    # Split output by device sections
    device_sections = _split_by_device(raw_output, device_map)

    for device, section in device_sections.items():
        for rule in script.parse_rules:
            pattern = rule.get("pattern", "")
            fact_key = rule.get("fact", "")
            threshold = rule.get("threshold")
            anomaly_if_above = rule.get("anomaly_if_above", False)
            is_anomaly = rule.get("anomaly", False)

            if not pattern or not fact_key:
                continue

            matches = re.findall(pattern, section, re.IGNORECASE)
            for match in matches:
                value = match if isinstance(match, str) else match[0] if match else ""

                # Check threshold-based anomaly detection
                anomaly = is_anomaly
                expected = None
                if threshold is not None and anomaly_if_above:
                    try:
                        num_value = int(value) if value.isdigit() else float(value)
                        if num_value > threshold:
                            anomaly = True
                            expected = f"<= {threshold}"
                    except (ValueError, TypeError):
                        pass

                # Get evidence context (line containing the match)
                evidence_lines = []
                for line in section.split("\n"):
                    if value and value in line:
                        evidence_lines.append(line.strip())
                        break

                facts.append(GatheredFact(
                    source_script=script.id,
                    device=device,
                    category=script.category.value,
                    key=fact_key,
                    value=value if isinstance(match, str) else match,
                    raw_evidence="\n".join(evidence_lines[:3]) if evidence_lines else "",
                    confidence=DataConfidence.MEDIUM,
                    timestamp=time.time(),
                    anomaly=anomaly,
                    expected=expected,
                ))

    return facts


def _split_by_device(raw_output: str, device_map: dict) -> dict[str, str]:
    """Split batch command output into per-device sections."""
    sections = {}
    current_device = "unknown"
    current_lines = []

    # Try JSON parse first
    try:
        data = json.loads(raw_output)
        for r in data.get("results", []):
            name = r.get("router_name", "unknown")
            output = r.get("output", "")
            sections[name] = output
        if sections:
            return sections
    except (json.JSONDecodeError, AttributeError):
        pass

    # Fall back to text parsing
    all_device_names = set()
    for mcp_name, hostname in device_map.items():
        all_device_names.add(mcp_name.lower())
        all_device_names.add(hostname.lower())

    for line in raw_output.split("\n"):
        stripped = line.strip()
        # Common separators in batch output
        if stripped.startswith("===") or stripped.startswith("---") or stripped.startswith("Router:"):
            if current_lines and current_device != "unknown":
                sections[current_device] = "\n".join(current_lines)
            current_lines = []
            # Extract device name
            for name in all_device_names:
                if name in stripped.lower():
                    # Find the MCP name
                    for mcp_name, hostname in device_map.items():
                        if mcp_name.lower() == name or hostname.lower() == name:
                            current_device = mcp_name
                            break
                    break
        current_lines.append(line)

    if current_lines and current_device != "unknown":
        sections[current_device] = "\n".join(current_lines)

    # If we couldn't parse sections, treat entire output as "all"
    if not sections:
        sections["all"] = raw_output

    return sections


async def execute_scripts_parallel(scripts: list[SmartScript],
                                    device_map: dict,
                                    run_batch_fn: Callable,
                                    run_single_fn: Callable,
                                    mcp_client, session_id,
                                    context: Optional[dict] = None,
                                    max_concurrent: int = 4) -> list[ScriptResult]:
    """Execute multiple scripts in parallel with concurrency limit.
    
    This is the core parallel execution engine — scripts run simultaneously
    while the AI can start analyzing completed results.
    """
    semaphore = asyncio.Semaphore(max_concurrent)

    async def _limited_execute(script):
        async with semaphore:
            return await execute_script(
                script, device_map, run_batch_fn, run_single_fn,
                mcp_client, session_id, context
            )

    tasks = [_limited_execute(s) for s in scripts]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Handle exceptions
    final_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            final_results.append(ScriptResult(
                script_id=scripts[i].id,
                script_name=scripts[i].name,
                status="failed",
                error=str(result),
            ))
        else:
            final_results.append(result)

    return final_results


# ══════════════════════════════════════════════════════════════
#  LAYER 1: ANALYSIS — AI Reads Script Results
# ══════════════════════════════════════════════════════════════

def compile_facts_summary(results: list[ScriptResult],
                          accumulator: Optional[FactAccumulator] = None) -> str:
    """Compile all gathered facts into a structured summary for the AI.

    v18.0: Integrates with FactAccumulator for deduplication and
    contradiction detection.  Uses professional icons instead of emojis.
    """
    sections = []

    # Group facts by device
    device_facts: dict[str, list[GatheredFact]] = {}
    all_anomalies: list[GatheredFact] = []

    source_facts = accumulator.all_facts if accumulator else []
    if not source_facts:
        for result in results:
            source_facts.extend(result.facts)

    for fact in source_facts:
        device_facts.setdefault(fact.device, []).append(fact)
        if fact.anomaly:
            all_anomalies.append(fact)

    # ── Anomalies first (most important for AI) ──
    if all_anomalies:
        sections.append("## ANOMALIES DETECTED")
        for anomaly in sorted(all_anomalies, key=lambda f: f.device):
            expected_str = f" (expected: {anomaly.expected})" if anomaly.expected else ""
            sections.append(
                f"- **{anomaly.device}** | {anomaly.key}: `{anomaly.value}`{expected_str}\n"
                f"  Evidence: {anomaly.raw_evidence[:200]}"
            )
    else:
        sections.append("## NO ANOMALIES DETECTED -- All Checks Passed")

    # ── Contradictions (v18.0) ──
    if accumulator and accumulator.contradictions:
        sections.append("\n## CONTRADICTIONS DETECTED")
        for fact_a, fact_b in accumulator.contradictions:
            sections.append(
                f"- **{fact_a.device}** | {fact_a.key}: "
                f"Source 1 says `{fact_a.value}`, Source 2 says `{fact_b.value}`"
            )

    # ── Cross-device anomaly matrix (v18.0) ──
    if accumulator:
        matrix = accumulator.device_anomaly_matrix()
        if matrix:
            sections.append("\n## CROSS-DEVICE ANOMALY MATRIX")
            all_cats = sorted(set(c for row in matrix.values() for c in row))
            header = "| Device | " + " | ".join(all_cats) + " |"
            sep = "|--------|" + "|".join("---" for _ in all_cats) + "|"
            sections.append(header)
            sections.append(sep)
            for dev in sorted(matrix):
                row = f"| {dev} | " + " | ".join(str(matrix[dev].get(c, 0)) for c in all_cats) + " |"
                sections.append(row)

    # ── Script execution summary ──
    sections.append("\n## SCRIPT EXECUTION SUMMARY")
    for result in results:
        status_icon = {"success": "[OK]", "failed": "[FAIL]", "timeout": "[TIMEOUT]", "partial": "[PARTIAL]"}.get(result.status, "[?]")
        sections.append(
            f"- {status_icon} **{result.script_name}**: {result.status} "
            f"({result.duration}s) | {len(result.facts)} facts | "
            f"{result.anomalies_found} anomalies | "
            f"Devices: {', '.join(result.devices_checked[:5])}"
        )

    # ── Per-device fact tables ──
    sections.append("\n## FACTS BY DEVICE")
    for device in sorted(device_facts.keys()):
        facts = device_facts[device]
        sections.append(f"\n### {device}")
        for fact in facts:
            icon = "[!]" if fact.anomaly else "[ok]"
            sections.append(f"  {icon} {fact.key}: {fact.value}")

    # ── Raw data for AI deep analysis ──
    sections.append("\n## RAW COMMAND OUTPUTS (for detailed analysis)")
    for result in results:
        if result.raw_output:
            sections.append(f"\n### {result.script_name}")
            # Truncate per-script raw output to keep total manageable
            truncated = result.raw_output[:3000]
            if len(result.raw_output) > 3000:
                truncated += f"\n... ({len(result.raw_output) - 3000} chars truncated)"
            sections.append(truncated)

    # ── Agentic hint: tell AI it can request probes ──
    sections.append(
        "\n## AI PROBE CAPABILITY\n"
        "If you need additional data from specific devices, output lines like:\n"
        "  PROBE: <device_name> | <show command> | <reason>\n"
        "The system will execute these commands and feed results back to you."
    )

    return "\n".join(sections)


def build_analysis_prompt(query: str, facts_summary: str, pass_number: int,
                          previous_analysis: str = "") -> str:
    """Build the analysis prompt for the AI."""

    if pass_number == 1:
        return (
            f"## INVESTIGATION QUERY\n{query}\n\n"
            f"## GATHERED DATA (from {pass_number} parallel smart scripts)\n"
            f"{facts_summary}\n\n"
            "## YOUR TASK — LAYER 1 ANALYSIS\n"
            "You are analyzing data gathered from live Junos routers.\n\n"
            "1. **Identify all issues** — List every anomaly with device, protocol, severity\n"
            "2. **Pattern recognition** — Are multiple devices affected? Is there a common cause?\n"
            "3. **Cross-correlation** — Does issue A on device X explain issue B on device Y?\n"
            "4. **OSI layer analysis** — Start from L1 (physical) up to services\n"
            "5. **Data gaps** — What additional data would help confirm your analysis?\n\n"
            "OUTPUT FORMAT:\n"
            "### Issues Found\n"
            "[list each issue with device, severity, evidence]\n\n"
            "### Cross-Correlation\n"
            "[how issues relate to each other]\n\n"
            "### Preliminary Root Cause\n"
            "[your best hypothesis — lowest layer failure that explains higher symptoms]\n\n"
            "### Data Gaps (CRITICAL)\n"
            "List SPECIFIC additional data you need:\n"
            "- GAP: [what's missing] | NEEDED: [specific show command] | WHY: [how it helps]\n\n"
            "### Agentic Probes (OPTIONAL)\n"
            "If you need data from a SPECIFIC device that the scripts did not gather, "
            "you may request targeted probes. Format EXACTLY:\n"
            "PROBE: <device_name> | <show command> | <reason>\n"
            "Example: PROBE: PE1 | show bgp summary | need to verify peer state\n"
            "Limit to 6 probes maximum. Only request what is truly needed.\n\n"
            "### Confidence\n"
            "CONFIDENCE: [0-100]% | REASON: [why this confidence level]\n"
        )
    else:
        return (
            f"## ORIGINAL QUERY\n{query}\n\n"
            f"## PREVIOUS ANALYSIS (Pass {pass_number - 1})\n"
            f"{previous_analysis[:3000]}\n\n"
            f"## NEW DATA (Pass {pass_number} — filling gaps identified above)\n"
            f"{facts_summary}\n\n"
            "## YOUR TASK — REFINED ANALYSIS (Double-Check Pass)\n"
            "You previously analyzed the network and identified gaps.\n"
            "New data has been gathered to fill those gaps.\n\n"
            "1. **Verify or refute** your previous hypotheses with the new data\n"
            "2. **Update confidence** — has the new data confirmed or contradicted your analysis?\n"
            "3. **Identify remaining gaps** — or confirm analysis is complete\n"
            "4. **Final root cause** — with full evidence chain\n\n"
            "If the new data CONTRADICTS your previous analysis, CHANGE YOUR CONCLUSION.\n"
            "If the new data CONFIRMS, increase confidence.\n\n"
            "OUTPUT FORMAT:\n"
            "### Updated Analysis\n"
            "[what changed with new data]\n\n"
            "### Root Cause (Updated)\n"
            "[confirmed or revised root cause]\n\n"
            "### Remaining Gaps\n"
            "[any remaining data needs — or 'NONE — analysis complete']\n\n"
            "### Confidence\n"
            "CONFIDENCE: [0-100]% | REASON: [why]\n"
        )


# ══════════════════════════════════════════════════════════════
#  LAYER 2: VALIDATION — Gap Detection & Double-Check
# ══════════════════════════════════════════════════════════════

def detect_validation_gaps(ai_analysis: str, existing_facts: list[GatheredFact],
                           executed_scripts: list[str]) -> list[ValidationGap]:
    """Parse AI analysis to find data gaps that need filling.
    
    The AI tells us what additional data it needs — we parse that
    and map it back to smart scripts.
    """
    gaps = []

    # ── Extract GAP mentions from AI analysis ──
    gap_patterns = [
        r"GAP:\s*(.+?)(?:\||\n)",
        r"NEEDED:\s*(.+?)(?:\||\n)",
        r"additional.*?(?:show\s+\S+(?:\s+\S+)*)",
        r"(?:need|require|want|missing).*?(?:show\s+\S+(?:\s+\S+)*)",
        r"Data Gaps.*?:\s*\n((?:.*?\n)*?)(?=###|\Z)",
    ]

    gap_text = ""
    # Find the "Data Gaps" section
    gap_section_match = re.search(
        r"(?:Data Gaps|Remaining Gaps|Additional Data|Missing Data).*?\n([\s\S]*?)(?=###|\Z)",
        ai_analysis, re.IGNORECASE
    )
    if gap_section_match:
        gap_text = gap_section_match.group(1)

    # Also look for inline gap mentions
    for pattern in gap_patterns:
        matches = re.findall(pattern, ai_analysis, re.IGNORECASE)
        for match in matches:
            gap_text += f"\n{match}"

    if not gap_text.strip() or "none" in gap_text.lower()[:50] or "complete" in gap_text.lower()[:50]:
        return []

    # ── Map gaps to scripts ──
    gap_to_script_map = {
        "ospf": ["ospf_deep", "ospf_state"],
        "bgp": ["bgp_deep", "bgp_state"],
        "ldp": ["ldp_deep", "ldp_mpls_state"],
        "mpls": ["ldp_deep", "ldp_mpls_state"],
        "isis": ["isis_deep", "isis_state"],
        "interface": ["intf_deep_dive", "intf_health"],
        "config": ["commit_history"],
        "optic": ["intf_deep_dive"],
        "vpn": ["vpn_state"],
        "security": ["security_posture"],
        "topology": ["topology_scan"],
        "performance": ["perf_baseline"],
        "route": ["route_validation"],
        "reachability": ["reachability_matrix"],
        "health": ["system_health"],
        "alarm": ["system_health"],
        "commit": ["commit_history"],
        "timer": ["ospf_deep", "isis_deep"],
        "mtu": ["ospf_deep", "intf_deep_dive"],
        "auth": ["ospf_deep", "bgp_deep", "isis_deep"],
        "policy": ["bgp_deep"],
        "prefix": ["bgp_deep"],
        "label": ["ldp_deep"],
    }

    # Parse gap text for keywords and map to scripts
    gap_lower = gap_text.lower()
    needed_scripts = set()

    for keyword, script_ids in gap_to_script_map.items():
        if keyword in gap_lower:
            for sid in script_ids:
                if sid not in executed_scripts:
                    needed_scripts.add(sid)

    # Also extract specific show commands mentioned
    show_commands = re.findall(r'show\s+(\S+(?:\s+\S+){0,3})', gap_text, re.IGNORECASE)
    for cmd_parts in show_commands:
        cmd_key = cmd_parts.split()[0].lower() if cmd_parts else ""
        for keyword, script_ids in gap_to_script_map.items():
            if keyword in cmd_key:
                for sid in script_ids:
                    if sid not in executed_scripts:
                        needed_scripts.add(sid)

    for sid in needed_scripts:
        gaps.append(ValidationGap(
            description=f"AI requested additional {sid.replace('_', ' ')} data",
            required_scripts=[sid],
            reason=f"Identified in gap analysis: {gap_text[:200]}",
            priority=3,
        ))

    return gaps


def extract_confidence_from_analysis(ai_analysis: str) -> float:
    """Extract the confidence percentage from AI analysis text."""
    # Try percentage format
    pct_match = re.search(r'CONFIDENCE:\s*(\d{1,3})%', ai_analysis, re.IGNORECASE)
    if pct_match:
        return float(pct_match.group(1))

    # Try decimal format
    dec_match = re.search(r'CONFIDENCE:\s*(0\.\d+)', ai_analysis, re.IGNORECASE)
    if dec_match:
        return float(dec_match.group(1)) * 100

    # Try word format
    word_match = re.search(r'CONFIDENCE:\s*(HIGH|MEDIUM|LOW|VERY HIGH|VERY LOW)',
                           ai_analysis, re.IGNORECASE)
    if word_match:
        word_map = {"very high": 95, "high": 85, "medium": 60, "low": 35, "very low": 15}
        return word_map.get(word_match.group(1).lower(), 50)

    return 50.0  # Default


# ══════════════════════════════════════════════════════════════
#  LAYER 3: SYNTHESIS — Final Response Builder
# ══════════════════════════════════════════════════════════════

def build_synthesis_prompt(query: str, all_analyses: list[str],
                           all_facts: list[GatheredFact],
                           total_passes: int) -> str:
    """Build the final synthesis prompt that produces the validated response."""
    
    # Count anomalies by category
    anomaly_summary = {}
    for fact in all_facts:
        if fact.anomaly:
            key = f"{fact.device}:{fact.key}"
            anomaly_summary[key] = fact

    anomaly_text = ""
    if anomaly_summary:
        anomaly_text = "### All Confirmed Anomalies\n"
        for key, fact in sorted(anomaly_summary.items()):
            expected_str = f" (expected: {fact.expected})" if fact.expected else ""
            anomaly_text += f"- **{fact.device}** | {fact.key}: `{fact.value}`{expected_str}\n"
    else:
        anomaly_text = "### No Anomalies Confirmed\n"

    analyses_combined = "\n\n---\n\n".join(
        f"### Pass {i+1} Analysis\n{a}" for i, a in enumerate(all_analyses)
    )

    return (
        f"## ORIGINAL QUERY\n{query}\n\n"
        f"## DATA COLLECTION: {total_passes} passes of parallel fact-gathering\n"
        f"## TOTAL FACTS GATHERED: {len(all_facts)} facts from {len(set(f.device for f in all_facts))} devices\n\n"
        f"{anomaly_text}\n\n"
        f"## ANALYSIS EVOLUTION (showing how understanding refined across passes)\n"
        f"{analyses_combined}\n\n"
        "## YOUR TASK — FINAL VALIDATED RESPONSE\n"
        "You have completed a multi-pass investigation with parallel data gathering and "
        "self-validation. Your analysis has been refined across multiple passes.\n\n"
        "Produce a FINAL, CONFIDENT, VALIDATED response:\n\n"
        "1. **Executive Summary** — 2-3 sentences a CTO can understand\n"
        "2. **Root Cause** — The single root cause (lowest OSI layer), with evidence\n"
        "3. **Cascading Chain** — How the root cause cascades to cause other symptoms\n"
        "4. **Evidence Chain** — For each finding, cite exact data\n"
        "5. **Fix** — Exact Junos `set`/`delete` commands in order\n"
        "6. **Verification** — Commands to verify the fix worked\n"
        "7. **Auto-Recovery** — What will heal automatically once root cause is fixed\n"
        "8. **Prevention** — How to prevent this in the future\n\n"
        "If the network is HEALTHY, clearly state that with evidence.\n\n"
        "CONFIDENCE REQUIREMENT: Your final confidence must be ≥70%.\n"
        "If it's lower, explain what additional investigation is needed.\n"
    )


# ══════════════════════════════════════════════════════════════
#  THE HYPERED BRAIN — MAIN ORCHESTRATOR
# ══════════════════════════════════════════════════════════════

async def hypered_brain_analyze(query: str,
                                 device_map: Optional[dict] = None,
                                 mcp_client: Any = None,
                                 session_id: str = "",
                                 run_batch_fn: Optional[Callable] = None,
                                 run_single_fn: Optional[Callable] = None,
                                 ai_analyze_fn: Optional[Callable] = None,
                                 console_fn: Optional[Callable] = None,
                                 print_fn: Optional[Callable] = None,
                                 confidence_threshold: float = 70.0,
                                 max_passes: int = 3,
                                 max_concurrent: int = 3,
                                 available_devices: Optional[list] = None) -> str:
    """The Hypered Brain — Multi-layer parallel AI analysis with self-validation.
    
    This is the main entry point. It orchestrates:
    1. PERCEPTION: Query → Script selection
    2. SCRIPTS: Parallel execution → Structured facts
    3. ANALYSIS: AI reads facts → Pattern recognition
    4. VALIDATION: Gap detection → Confidence check → Loop back if needed
    5. SYNTHESIS: Final validated response
    
    Args:
        query: User's question
        device_map: {mcp_name: hostname}
        mcp_client: HTTP client (passed through to run_batch_fn / run_single_fn)
        session_id: MCP session ID
        run_batch_fn: async fn(client, sid, cmd, routers, label) -> str
        run_single_fn: async fn(client, sid, cmd, router, label) -> str
        ai_analyze_fn: async fn(system_prompt, data, question) -> str
        console_fn: Rich console print function (optional)
        print_fn: Alias for console_fn
        confidence_threshold: Minimum confidence to accept analysis (0-100)
        max_passes: Maximum number of data-gathering passes
        max_concurrent: Max parallel scripts (semaphore limit)
        available_devices: Optional explicit device list (defaults to device_map keys)
    
    Returns:
        Complete validated analysis as markdown string
    """
    from rich.console import Console
    from rich.panel import Panel

    _console = print_fn or console_fn or Console().print
    if device_map is None:
        device_map = {}
    assert run_batch_fn is not None, "run_batch_fn is required"
    assert run_single_fn is not None, "run_single_fn is required"
    assert ai_analyze_fn is not None, "ai_analyze_fn is required"

    state = BrainState(
        query=query,
        start_time=time.time(),
        confidence_threshold=confidence_threshold,
        max_passes=max_passes,
    )

    all_analyses = []
    total_scripts_run = 0

    # ── v18.0 Agentic Components ──
    accumulator = FactAccumulator()
    adaptive = AdaptiveConcurrency(initial=max_concurrent, ceiling=6)

    _console(Panel(
        "[+] [bold cyan]HYPERED BRAIN v18.0[/bold cyan] -- Agentic Multi-Layer Parallel AI\n"
        f"Query: {query[:100]}{'...' if len(query) > 100 else ''}\n"
        f"Confidence threshold: {confidence_threshold}% | Max passes: {max_passes}\n"
        f"Adaptive concurrency: {adaptive.current} (auto-adjusting)",
        title="[*] Brain Activated",
        border_style="bold cyan",
        width=80,
    ))

    for pass_num in range(1, max_passes + 1):
        state.pass_number = pass_num
        pass_start = time.time()

        _console(f"\n   {'=' * 60}")
        _console(f"   [>] [bold]PASS {pass_num}/{max_passes}[/bold]")
        _console(f"   {'=' * 60}")

        # ==================================================
        #  LAYER 0: PERCEPTION -- Select Scripts
        # ==================================================
        state.layer = BrainLayer.PERCEPTION
        _console("   [>] [dim]Layer 0: PERCEPTION -- Selecting smart scripts...[/dim]")

        if pass_num == 1:
            scripts = select_scripts_for_query(
                query, SMART_SCRIPTS, state.script_results
            )
        else:
            # Use validation gaps to select follow-up scripts
            gap_scripts = []
            for gap in state.validation_gaps:
                for sid in gap.required_scripts:
                    if sid in SMART_SCRIPTS:
                        gap_scripts.append(SMART_SCRIPTS[sid])
            # Also check for follow-ups from anomalies
            follow_ups = select_follow_up_scripts(state.script_results, SMART_SCRIPTS)
            scripts = list({s.id: s for s in gap_scripts + follow_ups}.values())

        if not scripts:
            _console("   [ok] [green]No additional scripts needed -- analysis is complete[/green]")
            break

        _console(f"   [i] Selected {len(scripts)} scripts: "
                 f"{', '.join(s.name for s in scripts)}")

        # ==================================================
        #  LAYER 1: EXECUTION -- Parallel Script Execution
        # ==================================================
        current_concurrency = adaptive.current
        _console(f"   [>] [bold]Executing {len(scripts)} scripts in PARALLEL "
                 f"(concurrency: {current_concurrency})...[/bold]")

        # Build context from previous results (flagged devices, etc.)
        context = {}
        flagged_devices = []
        for result in state.script_results:
            for fact in result.facts:
                if fact.anomaly:
                    flagged_devices.append(fact.device)
        context["flagged_devices"] = list(set(flagged_devices))

        results = await execute_scripts_parallel(
            scripts, device_map, run_batch_fn, run_single_fn,
            mcp_client, session_id, context,
            max_concurrent=current_concurrency
        )

        state.script_results.extend(results)
        total_scripts_run += len(results)

        # Feed facts into accumulator for dedup, contradiction detection, anomaly matrix
        for result in results:
            accumulator.ingest(result.facts)
            state.all_facts.extend(result.facts)
            if result.status == "success":
                _console(f"      [ok] {result.script_name}: {len(result.facts)} facts, "
                         f"{result.anomalies_found} anomalies ({result.duration}s)")
            else:
                _console(f"      [x] {result.script_name}: {result.status} -- {result.error}")

        # Update adaptive concurrency with observed latencies
        for result in results:
            if result.duration and result.duration > 0:
                adaptive.record(result.duration)

        total_anomalies = sum(1 for f in state.all_facts if f.anomaly)
        contradictions = accumulator.contradictions
        state.contradictions = [
            f"{a.device}:{a.key} = {a.value} vs {b.value}" for a, b in contradictions
        ]

        _console(f"   [i] Total: {len(state.all_facts)} facts, {total_anomalies} anomalies, "
                 f"{len(contradictions)} contradictions")
        if contradictions:
            for c in state.contradictions[:3]:
                _console(f"      [!] CONTRADICTION: {c}")

        _console(f"   [i] Adaptive concurrency: {adaptive.current} "
                 f"(was {current_concurrency})")

        # ==================================================
        #  LAYER 2: ANALYSIS -- AI Reads Script Results
        # ==================================================
        state.layer = BrainLayer.ANALYSIS
        _console("   [>] [dim]Layer 2: ANALYSIS -- AI processing gathered data...[/dim]")

        facts_summary = compile_facts_summary(results, accumulator=accumulator)
        analysis_prompt = build_analysis_prompt(
            query, facts_summary, pass_num,
            all_analyses[-1] if all_analyses else ""
        )

        ai_analysis = await ai_analyze_fn(
            "You are a JNCIE-SP network architect performing multi-layer analysis. "
            "You are part of the Hypered Brain v18.0 -- an agentic multi-pass parallel AI system. "
            "Your analysis will be validated and you may get additional data if needed. "
            "You may request targeted probes using PROBE: <device> | <command> | <reason>. "
            "Be precise, cite evidence, and clearly state your confidence level.",
            facts_summary[:8000],
            analysis_prompt,
            True  # include_kb
        )

        all_analyses.append(ai_analysis)
        _console(f"   [i] Analysis complete: {len(ai_analysis)} chars")

        # ==================================================
        #  LAYER 2.5: AGENTIC PROBES -- AI-Directed Commands
        # ==================================================
        probes = extract_ai_probes(ai_analysis, device_map)
        if probes:
            _console(f"   [>] [bold magenta]AGENTIC PROBING -- AI requested "
                     f"{len(probes)} targeted probes[/bold magenta]")
            for p in probes:
                _console(f"      [>] {p.device}: {p.command} ({p.reason})")

            probe_results = await execute_ai_probes(
                probes, run_single_fn, mcp_client,
                session_id, adaptive
            )

            # Feed probe results back into state
            for pr in probe_results:
                accumulator.ingest(pr.facts)
                state.all_facts.extend(pr.facts)
                state.script_results.append(pr)
                if pr.status == "success":
                    _console(f"      [ok] Probe {pr.script_name}: "
                             f"{len(pr.facts)} facts ({pr.duration}s)")
                else:
                    _console(f"      [x] Probe {pr.script_name}: {pr.error}")

            # Refresh summary with probe data
            facts_summary = compile_facts_summary(
                state.script_results, accumulator=accumulator
            )

        # ==================================================
        #  LAYER 3: VALIDATION -- Gap Detection & Confidence
        # ==================================================
        state.layer = BrainLayer.VALIDATION
        _console("   [>] [dim]Layer 3: VALIDATION -- Checking gaps & confidence...[/dim]")

        # Extract confidence
        state.confidence_score = extract_confidence_from_analysis(ai_analysis)
        _console(f"   [i] Confidence: {state.confidence_score}%"
                 f" (threshold: {confidence_threshold}%)")

        # Detect gaps
        executed_ids = [r.script_id for r in state.script_results]
        state.validation_gaps = detect_validation_gaps(
            ai_analysis, state.all_facts, executed_ids
        )

        if state.validation_gaps:
            _console(f"   [!] {len(state.validation_gaps)} data gaps identified:")
            for gap in state.validation_gaps[:3]:
                _console(f"      -> {gap.description}")

        # ==================================================
        #  DECISION: Continue or Stop?
        # ==================================================
        pass_time = round(time.time() - pass_start, 1)
        state.layer_timings[f"pass_{pass_num}"] = pass_time
        _console(f"   [t] Pass {pass_num} complete in {pass_time}s")

        if state.confidence_score >= confidence_threshold:
            if not state.validation_gaps:
                _console(f"   [ok] [bold green]Confidence {state.confidence_score}% >= {confidence_threshold}% "
                         f"with no gaps -- analysis validated![/bold green]")
                break
            else:
                _console(f"   [>] Confidence is sufficient but gaps remain -- one more pass...")
                if pass_num >= max_passes:
                    _console(f"   [!] Max passes reached -- proceeding with current analysis")
                    break
        else:
            if pass_num >= max_passes:
                _console(f"   [!] [yellow]Confidence {state.confidence_score}% < {confidence_threshold}% "
                         f"but max passes reached -- proceeding with best analysis[/yellow]")
                break
            else:
                _console(f"   [>] [yellow]Confidence {state.confidence_score}% < {confidence_threshold}% "
                         f"-- triggering double-check pass...[/yellow]")

    # ══════════════════════════════════════════════════════════
    #  LAYER 4: SYNTHESIS — Final Validated Response
    # ══════════════════════════════════════════════════════════
    state.layer = BrainLayer.SYNTHESIS
    _console("\n   [>] [bold]Layer 4: SYNTHESIS -- Building validated response...[/bold]")

    synthesis_prompt = build_synthesis_prompt(
        query, all_analyses, state.all_facts, state.pass_number
    )

    final_response = await ai_analyze_fn(
        "You are the Chief Network Architect in the Hypered Brain v18.0 system. "
        "You have completed a thorough multi-pass investigation with parallel data gathering, "
        "agentic probing, AI analysis, gap detection, and self-validation. "
        "Produce the FINAL, DEFINITIVE, VALIDATED response. "
        "Every finding must cite exact evidence from the gathered data. "
        "Do NOT speculate — if data is insufficient, say so explicitly.",
        "\n\n".join(all_analyses)[:10000],
        synthesis_prompt,
        True  # include_kb
    )

    # ── Build the complete response with metadata ──
    total_time = round(time.time() - state.start_time, 1)
    total_facts = len(state.all_facts)
    total_anomalies = sum(1 for f in state.all_facts if f.anomaly)
    devices_checked = len(set(f.device for f in state.all_facts))

    metadata = (
        f"\n\n---\n"
        f"### Hypered Brain v18.0 Metadata\n"
        f"- **Passes:** {state.pass_number} | **Scripts Run:** {total_scripts_run}\n"
        f"- **Facts Gathered:** {total_facts} | **Anomalies:** {total_anomalies}\n"
        f"- **Contradictions Detected:** {len(state.contradictions)}\n"
        f"- **Devices Checked:** {devices_checked}\n"
        f"- **Final Confidence:** {state.confidence_score}%\n"
        f"- **Adaptive Concurrency Final:** {adaptive.current}\n"
        f"- **Total Time:** {total_time}s\n"
        f"- **Pass Timings:** {json.dumps(state.layer_timings)}\n"
    )

    state.final_response = final_response + metadata

    _console(Panel(
        f"[ok] Analysis complete in {total_time}s\n"
        f"[i] {total_facts} facts | {total_anomalies} anomalies | "
        f"{state.pass_number} passes | {state.confidence_score}% confidence",
        title="[+] Hypered Brain Complete",
        border_style="bold green",
        width=80,
    ))

    return state.final_response


# ══════════════════════════════════════════════════════════════
#  UTILITY: Quick Brain (for simple queries)
# ══════════════════════════════════════════════════════════════

async def quick_brain_analyze(query: str,
                               device_map: Optional[dict] = None,
                               mcp_client: Any = None,
                               session_id: str = "",
                               run_batch_fn: Optional[Callable] = None,
                               run_single_fn: Optional[Callable] = None,
                               ai_analyze_fn: Optional[Callable] = None,
                               console_fn: Optional[Callable] = None,
                               print_fn: Optional[Callable] = None,
                               max_concurrent: int = 3,
                               available_devices: Optional[list] = None) -> str:
    """Lightweight version of Hypered Brain for simple queries.
    
    Single pass, no validation loop — for quick status checks
    and simple questions that don't need full multi-pass analysis.
    """
    return await hypered_brain_analyze(
        query=query,
        device_map=device_map,
        mcp_client=mcp_client,
        session_id=session_id,
        run_batch_fn=run_batch_fn,
        run_single_fn=run_single_fn,
        ai_analyze_fn=ai_analyze_fn,
        console_fn=console_fn,
        print_fn=print_fn,
        confidence_threshold=50.0,  # Lower threshold for quick queries
        max_passes=1,  # Single pass only
        max_concurrent=max_concurrent,
        available_devices=available_devices,
    )


# ══════════════════════════════════════════════════════════════
#  PUBLIC API — What gets imported into ollama_mcp_client.py
# ══════════════════════════════════════════════════════════════

__all__ = [
    # Core engine
    "hypered_brain_analyze",
    "quick_brain_analyze",
    # Data structures
    "BrainState",
    "BrainLayer",
    "SmartScript",
    "ScriptCategory",
    "ScriptResult",
    "GatheredFact",
    "ValidationGap",
    "DataConfidence",
    # v18.0 Agentic components
    "FactAccumulator",
    "AdaptiveConcurrency",
    "AIProbe",
    "extract_ai_probes",
    "execute_ai_probes",
    # Script library
    "SMART_SCRIPTS",
    "select_scripts_for_query",
    "select_follow_up_scripts",
    # Execution
    "execute_script",
    "execute_scripts_parallel",
    # Analysis helpers
    "compile_facts_summary",
    "build_analysis_prompt",
    "detect_validation_gaps",
    "extract_confidence_from_analysis",
    "build_synthesis_prompt",
]
