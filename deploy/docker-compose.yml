version: "3.9"
# ═══════════════════════════════════════════════════════════════
#  Junos AI NOC — Production Docker Compose Stack
#  Services: PostgreSQL, Redis, Web UI, Celery Workers, Nginx, Ollama
# ═══════════════════════════════════════════════════════════════

services:

  # ── PostgreSQL (all application state) ──────────────────────
  postgres:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: junos_noc
      POSTGRES_USER: noc_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD in .env}
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./migrations/001_init.sql:/docker-entrypoint-initdb.d/001_init.sql
    ports:
      - "127.0.0.1:5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U noc_user -d junos_noc"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # ── Redis (SocketIO message bus + Celery broker + cache) ────
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: >
      redis-server
        --maxmemory 256mb
        --maxmemory-policy allkeys-lru
        --requirepass ${REDIS_PASSWORD:-}
    ports:
      - "127.0.0.1:6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ── Junos AI NOC — Web Application ─────────────────────────
  noc-web:
    build:
      context: ../
      dockerfile: deploy/Dockerfile
    restart: unless-stopped
    environment:
      NOC_PORT: "5555"
      NOC_HOST: "0.0.0.0"
      NOC_DB_MODE: postgres
      DATABASE_URL: postgresql://noc_user:${POSTGRES_PASSWORD}@postgres:5432/junos_noc
      REDIS_URL: redis://redis:6379/0
      NOC_API_KEY: ${NOC_API_KEY:-}
      FLASK_SECRET_KEY: ${FLASK_SECRET_KEY:?Set FLASK_SECRET_KEY in .env}
      NOC_WORKERS: ${NOC_WORKERS:-3}
    command: >
      gunicorn
        --config deploy/gunicorn.conf.py
        --worker-class eventlet
        app:app
    working_dir: /app/web_ui
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "127.0.0.1:5555:5555"
    volumes:
      - ../golden_configs:/app/golden_configs
      - ../templates:/app/templates
      - ../logs:/app/logs
      - ../conversations:/app/conversations
      - ../config.yaml:/app/config.yaml:ro
      - ../junos-mcp-server/devices.json:/app/junos-mcp-server/devices.json:ro

  # ── Celery Worker (background tasks: MCP batch, AI analysis) ─
  celery-worker:
    build:
      context: ../
      dockerfile: deploy/Dockerfile
    restart: unless-stopped
    command: >
      celery -A deploy.celery_worker worker
        --loglevel=info
        --concurrency=4
        --max-tasks-per-child=100
    working_dir: /app
    environment:
      DATABASE_URL: postgresql://noc_user:${POSTGRES_PASSWORD}@postgres:5432/junos_noc
      REDIS_URL: redis://redis:6379/0
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ../golden_configs:/app/golden_configs
      - ../config.yaml:/app/config.yaml:ro

  # ── Celery Beat (periodic task scheduler — replaces daemon thread) ─
  celery-beat:
    build:
      context: ../
      dockerfile: deploy/Dockerfile
    restart: unless-stopped
    command: >
      celery -A deploy.celery_worker beat
        --loglevel=info
        --schedule=/tmp/celerybeat-schedule
    working_dir: /app
    environment:
      DATABASE_URL: postgresql://noc_user:${POSTGRES_PASSWORD}@postgres:5432/junos_noc
      REDIS_URL: redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy

  # ── Nginx (TLS termination, static files, rate limiting) ────
  nginx:
    image: nginx:1.27-alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./certs:/etc/ssl:ro
      - ../web_ui/static:/opt/junos-noc/web_ui/static:ro
    depends_on:
      - noc-web

  # ── Ollama (Local AI inference) ─────────────────────────────
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports:
      - "127.0.0.1:11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    # Uncomment for GPU acceleration:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

volumes:
  pgdata:
    driver: local
  ollama_models:
    driver: local
